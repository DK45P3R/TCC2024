import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.utils import resample
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import LambdaCallback
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
import matplotlib.pyplot as plt
import csv

# Função de callback para imprimir informações sobre o número de amostras
def on_epoch_end(epoch, logs):
    print(f"\nÉpoca {epoch + 1}:")
    print(f"Número de amostras no treino: {X_train.shape[0]}")
    print(f"Número de amostras no teste: {X_test.shape[0]}")

# Função para carregar e preparar os dados
def carregar_dados(csv_file_benign, csv_file_malign):
    num_cols_benign = pd.read_csv(csv_file_benign, encoding='ISO-8859-1', sep=';', quoting=csv.QUOTE_NONE, on_bad_lines='skip').shape[1]
    num_cols_malign = pd.read_csv(csv_file_malign, encoding='ISO-8859-1', sep=';', quoting=csv.QUOTE_NONE, on_bad_lines='skip').shape[1]
    max_num_cols = max(num_cols_benign, num_cols_malign)

    data_benign = pd.read_csv(csv_file_benign, encoding='ISO-8859-1', sep=';', names=range(max_num_cols), quoting=csv.QUOTE_NONE, on_bad_lines='warn')
    data_malign = pd.read_csv(csv_file_malign, encoding='ISO-8859-1', sep=';', names=range(max_num_cols), quoting=csv.QUOTE_NONE, on_bad_lines='warn')

    data_benign['classe'] = 'benigno'
    data_malign['classe'] = 'maligno'
    data_benign_downsampled = resample(data_benign, replace=False, n_samples=len(data_malign), random_state=42)
    data_full = pd.concat([data_benign_downsampled, data_malign], axis=0)

    X = data_full.iloc[:, :-1].apply(pd.to_numeric, errors='coerce').fillna(0)
    y = data_full.iloc[:, -1]

    label_encoder = LabelEncoder()
    y = label_encoder.fit_transform(y)
    X = X.astype(np.float32)
    y = y.astype(np.int32)

    return X, y

# Função para criar e treinar o modelo MLP
def treinar_modelo(X, y, input_dim, dropout_rate=0.2, epochs=50):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    y_train = to_categorical(y_train, num_classes=2)
    y_test = to_categorical(y_test, num_classes=2)

    model = Sequential([
        Dense(256, activation='sigmoid', input_shape=(input_dim,)),
        Dropout(dropout_rate),
        Dense(256, activation='relu'),
        Dense(2, activation='softmax')
    ])
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

    print_callback = LambdaCallback(on_epoch_end=on_epoch_end)
    history = model.fit(X_train, y_train, batch_size=32, epochs=epochs, validation_data=(X_test, y_test), callbacks=[print_callback])

    y_pred = model.predict(X_test)
    y_pred_classes = np.argmax(y_pred, axis=1)
    y_test_classes = np.argmax(y_test, axis=1)

    return y_test_classes, y_pred_classes, y_test, y_pred, model, history

dados = {
    'API Calls': ('api_calls_2b.csv', 'api_calls_2m.csv'),
    'Opcodes': ('opcodes_2b.csv', 'opcodes_2m.csv'),
    'Permissions': ('permissions_2b.csv', 'permissions_2m.csv')
}

classification_reports = []
confusion_matrices = []
histories = []
roc_curves = []

for nome, (csv_b, csv_m) in dados.items():
    X, y = carregar_dados(csv_b, csv_m)
    y_test_classes, y_pred_classes, y_test, y_pred, model, history = treinar_modelo(X, y, input_dim=X.shape[1], epochs=50)
    report = classification_report(y_test_classes, y_pred_classes, target_names=['benigno', 'maligno'])
    conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)

    classification_reports.append((nome, report))
    confusion_matrices.append((nome, conf_matrix))
    histories.append((nome, history))

    # Calcular a curva ROC e AUC para o modelo atual
    fpr, tpr, _ = roc_curve(y_test[:, 1], y_pred[:, 1])
    roc_auc = auc(fpr, tpr)
    roc_curves.append((nome, fpr, tpr, roc_auc))

    model.save(f'MLP_{nome}.h5')
    print(f"Modelo salvo como 'MLP_{nome}.h5'")

# Exibir os relatórios de classificação
for model_name, report in classification_reports:
    print(f"\nRelatório de Classificação para {model_name}:\n{report}")

# Plotar as matrizes de confusão
fig, axes = plt.subplots(1, 3, figsize=(15, 5))
for ax, (model_name, conf_matrix) in zip(axes, confusion_matrices):
    cax = ax.matshow(conf_matrix, cmap='Blues')
    fig.colorbar(cax, ax=ax)
    ax.set_title(f'{model_name} Confusion Matrix')
    ax.set_xlabel('Predito')
    ax.set_ylabel('Verdadeiro')
    ax.set_xticklabels([''] + ['benigno', 'maligno'])
    ax.set_yticklabels([''] + ['benigno', 'maligno'])

plt.tight_layout()
plt.show()

# Plotar os gráficos de precisão (acurácia) ao longo das épocas
plt.figure(figsize=(10, 5))
for model_name, history in histories:
    plt.plot(history.history['accuracy'], label=f'{model_name} Treino')
    plt.plot(history.history['val_accuracy'], label=f'{model_name} Validação')
plt.title('Acurácia do Modelo por Época')
plt.xlabel('Época')
plt.ylabel('Acurácia')
plt.legend()
plt.show()

# Plotar as curvas ROC
plt.figure(figsize=(10, 5))
for model_name, fpr, tpr, roc_auc in roc_curves:
    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], 'k--')  # Diagonal de chance
plt.title('Curva ROC')
plt.xlabel('Taxa de Falsos Positivos')
plt.ylabel('Taxa de Verdadeiros Positivos')
plt.legend(loc='lower right')
plt.show()
