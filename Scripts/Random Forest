import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc
import matplotlib.pyplot as plt
import seaborn as sns
import pickle

# Função para treinar e avaliar o modelo RandomForest para cada conjunto de dados
def train_and_evaluate_rf(data_benign_path, data_malign_path, model_name, n_estimators=100):
    # Carregar os arquivos CSV
    data_benign = pd.read_csv(data_benign_path, encoding='ISO-8859-1', sep=';', index_col=False, on_bad_lines='skip')
    data_malign = pd.read_csv(data_malign_path, encoding='ISO-8859-1', sep=';', index_col=False, on_bad_lines='skip')

    # Adicionar coluna de rótulo
    data_malign['label'] = 1
    data_benign['label'] = 0

    # Remover a coluna "Nome do Arquivo" de cada dataset
    data_benign = data_benign.drop(columns=['Nome do Arquivo'])
    data_malign = data_malign.drop(columns=['Nome do Arquivo'])

    # Concatenar os dados
    data = pd.concat([data_malign, data_benign], ignore_index=True)

    # Preencher valores faltantes com 0 e manter apenas colunas numéricas
    data = data.fillna(0).select_dtypes(include=[float, int])

    # Separar características e rótulos
    X = data.drop('label', axis=1)
    y = data['label']

    # Dividir os dados em conjuntos de treinamento e teste
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

    # Treinar o modelo Random Forest
    model_rf = RandomForestClassifier(n_estimators=n_estimators, random_state=3)
    model_rf.fit(X_train, y_train)

    # Fazer previsões e calcular a acurácia
    y_pred = model_rf.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f'\nAcurácia do teste para {model_name}:', accuracy)

    # Gerar relatório de classificação
    report = classification_report(y_test, y_pred, target_names=['benigno', 'maligno'])
    print(f"\nRelatório de Classificação para {model_name}:\n", report)

    # Exibir a matriz de confusão
    conf_matrix = confusion_matrix(y_test, y_pred)
    print(f"Matriz de Confusão para {model_name}:\n", conf_matrix)

    # Gráfico de Matriz de Confusão
    plt.figure(figsize=(5, 4))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=['Benigno', 'Maligno'], yticklabels=['Benigno', 'Maligno'])
    plt.xlabel("Classe Predita")
    plt.ylabel("Classe Verdadeira")
    plt.title(f"Matriz de Confusão para {model_name}")
    plt.show()

    # Curva ROC
    y_pred_prob = model_rf.predict_proba(X_test)[:, 1]
    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
    roc_auc = auc(fpr, tpr)

    plt.figure(2)
    plt.plot(fpr, tpr, lw=2, label=f"{model_name} (área = {roc_auc:.2f})")
    plt.plot([0, 1], [0, 1], color='grey', linestyle='--')
    plt.xlabel("Taxa de Falso Positivo")
    plt.ylabel("Taxa de Verdadeiro Positivo")
    plt.title(f"Curva ROC para {model_name}")
    plt.legend(loc="lower right")
    plt.show()

    # Salvando o modelo treinado
    arquivo_pickle = f"RandomForest_{model_name}.sav"
    pickle.dump(model_rf, open(arquivo_pickle, 'wb'))

# Chamando a função para os três conjuntos de dados
train_and_evaluate_rf('api_calls_2b.csv', 'api_calls_2m.csv', 'API_Calls')
train_and_evaluate_rf('opcodes_2b.csv', 'opcodes_2m.csv', 'Opcodes')
train_and_evaluate_rf('permissions_2b.csv', 'permissions_2m.csv', 'Permissions')
