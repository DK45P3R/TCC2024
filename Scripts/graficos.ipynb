#graficos

'''
Comentado para teste de performance

# Salvar histórico do treinamento
history = model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test), callbacks=[print_callback])

# Salvar relatório de classificação e matriz de confusão em dicionários
classification_reports['API Calls'] = classification_report(y_test_classes, y_pred_classes, output_dict=True)
confusion_matrices['API Calls'] = conf_matrix

# Adicione o código para os outros modelos também
'''

Modelo MLP

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.utils import resample
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import LambdaCallback
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
import matplotlib.pyplot as plt
import csv

# Função de callback para imprimir informações sobre o número de amostras
def on_epoch_end(epoch, logs):
    print(f"\nÉpoca {epoch + 1}:")
    print(f"Número de amostras no treino: {X_train.shape[0]}")
    print(f"Número de amostras no teste: {X_test.shape[0]}")

# Função para carregar e preparar os dados
def carregar_dados(csv_file_benign, csv_file_malign):
    num_cols_benign = pd.read_csv(csv_file_benign, encoding='ISO-8859-1', sep=';', quoting=csv.QUOTE_NONE, on_bad_lines='skip').shape[1]
    num_cols_malign = pd.read_csv(csv_file_malign, encoding='ISO-8859-1', sep=';', quoting=csv.QUOTE_NONE, on_bad_lines='skip').shape[1]
    max_num_cols = max(num_cols_benign, num_cols_malign)

    data_benign = pd.read_csv(csv_file_benign, encoding='ISO-8859-1', sep=';', names=range(max_num_cols), quoting=csv.QUOTE_NONE, on_bad_lines='warn')
    data_malign = pd.read_csv(csv_file_malign, encoding='ISO-8859-1', sep=';', names=range(max_num_cols), quoting=csv.QUOTE_NONE, on_bad_lines='warn')

    data_benign['classe'] = 'benigno'
    data_malign['classe'] = 'maligno'
    data_benign_downsampled = resample(data_benign, replace=False, n_samples=len(data_malign), random_state=42)
    data_full = pd.concat([data_benign_downsampled, data_malign], axis=0)

    X = data_full.iloc[:, :-1].apply(pd.to_numeric, errors='coerce').fillna(0)
    y = data_full.iloc[:, -1]

    label_encoder = LabelEncoder()
    y = label_encoder.fit_transform(y)
    X = X.astype(np.float32)
    y = y.astype(np.int32)

    return X, y

# Função para criar e treinar o modelo MLP
def treinar_modelo(X, y, input_dim, dropout_rate=0.2, epochs=50):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    y_train = to_categorical(y_train, num_classes=2)
    y_test = to_categorical(y_test, num_classes=2)

    model = Sequential([
        Dense(256, activation='sigmoid', input_shape=(input_dim,)),
        Dropout(dropout_rate),
        Dense(256, activation='relu'),
        Dense(2, activation='softmax')
    ])
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

    print_callback = LambdaCallback(on_epoch_end=on_epoch_end)
    history = model.fit(X_train, y_train, batch_size=32, epochs=epochs, validation_data=(X_test, y_test), callbacks=[print_callback])

    y_pred = model.predict(X_test)
    y_pred_classes = np.argmax(y_pred, axis=1)
    y_test_classes = np.argmax(y_test, axis=1)

    return y_test_classes, y_pred_classes, y_test, y_pred, model, history

dados = {
    'API Calls': ('api_calls_2b.csv', 'api_calls_2m.csv'),
    'Opcodes': ('opcodes_2b.csv', 'opcodes_2m.csv'),
    'Permissions': ('permissions_2b.csv', 'permissions_2m.csv')
}

classification_reports = []
confusion_matrices = []
histories = []
roc_curves = []

for nome, (csv_b, csv_m) in dados.items():
    X, y = carregar_dados(csv_b, csv_m)
    y_test_classes, y_pred_classes, y_test, y_pred, model, history = treinar_modelo(X, y, input_dim=X.shape[1], epochs=50)
    report = classification_report(y_test_classes, y_pred_classes, target_names=['benigno', 'maligno'])
    conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)

    classification_reports.append((nome, report))
    confusion_matrices.append((nome, conf_matrix))
    histories.append((nome, history))

    # Calcular a curva ROC e AUC para o modelo atual
    fpr, tpr, _ = roc_curve(y_test[:, 1], y_pred[:, 1])
    roc_auc = auc(fpr, tpr)
    roc_curves.append((nome, fpr, tpr, roc_auc))

    model.save(f'MLP_{nome}.h5')
    print(f"Modelo salvo como 'MLP_{nome}.h5'")

# Exibir os relatórios de classificação
for model_name, report in classification_reports:
    print(f"\nRelatório de Classificação para {model_name}:\n{report}")

# Plotar as matrizes de confusão
fig, axes = plt.subplots(1, 3, figsize=(15, 5))
for ax, (model_name, conf_matrix) in zip(axes, confusion_matrices):
    cax = ax.matshow(conf_matrix, cmap='Blues')
    fig.colorbar(cax, ax=ax)
    ax.set_title(f'{model_name} Confusion Matrix')
    ax.set_xlabel('Predito')
    ax.set_ylabel('Verdadeiro')
    ax.set_xticklabels([''] + ['benigno', 'maligno'])
    ax.set_yticklabels([''] + ['benigno', 'maligno'])

plt.tight_layout()
plt.show()

# Plotar os gráficos de precisão (acurácia) ao longo das épocas
plt.figure(figsize=(10, 5))
for model_name, history in histories:
    plt.plot(history.history['accuracy'], label=f'{model_name} Treino')
    plt.plot(history.history['val_accuracy'], label=f'{model_name} Validação')
plt.title('Acurácia do Modelo por Época')
plt.xlabel('Época')
plt.ylabel('Acurácia')
plt.legend()
plt.show()

# Plotar as curvas ROC
plt.figure(figsize=(10, 5))
for model_name, fpr, tpr, roc_auc in roc_curves:
    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], 'k--')  # Diagonal de chance
plt.title('Curva ROC')
plt.xlabel('Taxa de Falsos Positivos')
plt.ylabel('Taxa de Verdadeiros Positivos')
plt.legend(loc='lower right')
plt.show()


Modelo KNN

import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pickle

# Função para treinar e avaliar o modelo KNN para um conjunto de dados específico
def train_and_evaluate_knn(data_benign_path, data_malign_path, model_name):
    # Carregar os arquivos CSV
    data_benign = pd.read_csv(data_benign_path, encoding='ISO-8859-1', sep=';', on_bad_lines='skip')
    data_malign = pd.read_csv(data_malign_path, encoding='ISO-8859-1', sep=';', on_bad_lines='skip')

    # Adicionar coluna de rótulo
    data_malign['label'] = 1
    data_benign['label'] = 0

    # Remover a coluna "Nome do Arquivo" de cada dataset
    data_benign = data_benign.drop(columns=['Nome do Arquivo'])
    data_malign = data_malign.drop(columns=['Nome do Arquivo'])

    # Concatenar os dados
    data = pd.concat([data_benign, data_malign], ignore_index=True)

    # Preencher valores faltantes com 0
    data = data.fillna(0)

    # Remover colunas não numéricas (como hashes, nomes de arquivos, etc.)
    data = data.apply(pd.to_numeric, errors='coerce').fillna(0)

    # Separar características e rótulos
    X = data.drop('label', axis=1)
    y = data['label']

    # Dividir os dados em conjuntos de treinamento e teste
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

    # Padronizar os dados com StandardScaler
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    # Definir o intervalo de valores para n_neighbors
    param_grid = {'n_neighbors': [1, 3, 5, 7, 9, 11, 15, 20, 50, 75, 100]}

    # Realizar busca em grid para encontrar o melhor n_neighbors
    grid_search = GridSearchCV(KNeighborsClassifier(weights='distance'), param_grid, cv=5, scoring='accuracy')
    grid_search.fit(X_train, y_train)

    # Melhor valor de n_neighbors encontrado
    best_n_neighbors = grid_search.best_params_['n_neighbors']
    print(f"\nMelhor valor de n_neighbors para {model_name}: {best_n_neighbors}")

    # Usar o melhor modelo encontrado no GridSearch
    knn_best = grid_search.best_estimator_

    # Fazer previsões com o melhor modelo
    y_pred = knn_best.predict(X_test)
    y_pred_prob = knn_best.predict_proba(X_test)[:, 1]

    # Gerar o relatório de classificação
    report = classification_report(y_test, y_pred, target_names=['benigno', 'maligno'])
    print(f"\nRelatório de Classificação para {model_name}:\n", report)

    # Exibir a matriz de confusão
    conf_matrix = confusion_matrix(y_test, y_pred)
    print(f"Matriz de Confusão para {model_name}:\n", conf_matrix)

    # Gráfico de Acurácia (Validação Cruzada)
    cv_scores = cross_val_score(knn_best, X, y, cv=5)
    print(f"\nValidação Cruzada (5-fold) - Acurácia Média para {model_name}:", cv_scores.mean())

    # Adicionar curva de acurácia ao gráfico de acurácia
    plt.figure(1)
    plt.plot(range(1, 6), cv_scores, marker='o', label=f"Acurácia ({model_name})")

    # Gráfico ROC
    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
    roc_auc = auc(fpr, tpr)

    plt.figure(2)
    plt.plot(fpr, tpr, lw=2, label=f"{model_name} (área = {roc_auc:.2f})")

    # Gráfico de Matriz de Confusão
    plt.figure(figsize=(5, 4))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=['Benigno', 'Maligno'], yticklabels=['Benigno', 'Maligno'])
    plt.xlabel("Classe Predita")
    plt.ylabel("Classe Verdadeira")
    plt.title(f"Matriz de Confusão para {model_name}")
    plt.show()

    # Salvando o modelo treinado
    arquivo_pickle = f"KNN_{model_name}_best.sav"
    pickle.dump(knn_best, open(arquivo_pickle, 'wb'))

# Chamando a função para os três conjuntos de dados
train_and_evaluate_knn('api_calls_2b.csv', 'api_calls_2m.csv', 'API_Calls')
train_and_evaluate_knn('opcodes_2b.csv', 'opcodes_2m.csv', 'Opcodes')
train_and_evaluate_knn('permissions_2b.csv', 'permissions_2m.csv', 'Permissions')

# Ajustando e exibindo o gráfico de acurácia
plt.figure(1)
plt.title("Acurácia da Validação Cruzada (5-fold)")
plt.xlabel("Fold")
plt.ylabel("Acurácia")
plt.grid()
plt.legend()
plt.show()

# Ajustando e exibindo o gráfico de ROC
plt.figure(2)
plt.plot([0, 1], [0, 1], color='grey', linestyle='--')
plt.xlabel("Taxa de Falso Positivo")
plt.ylabel("Taxa de Verdadeiro Positivo")
plt.title("Curva ROC")
plt.legend(loc="lower right")
plt.show()


Modelo Random Forest

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc
import matplotlib.pyplot as plt
import seaborn as sns
import pickle

# Função para treinar e avaliar o modelo RandomForest para cada conjunto de dados
def train_and_evaluate_rf(data_benign_path, data_malign_path, model_name, n_estimators=100):
    # Carregar os arquivos CSV
    data_benign = pd.read_csv(data_benign_path, encoding='ISO-8859-1', sep=';', index_col=False, on_bad_lines='skip')
    data_malign = pd.read_csv(data_malign_path, encoding='ISO-8859-1', sep=';', index_col=False, on_bad_lines='skip')

    # Adicionar coluna de rótulo
    data_malign['label'] = 1
    data_benign['label'] = 0

    # Remover a coluna "Nome do Arquivo" de cada dataset
    data_benign = data_benign.drop(columns=['Nome do Arquivo'])
    data_malign = data_malign.drop(columns=['Nome do Arquivo'])

    # Concatenar os dados
    data = pd.concat([data_malign, data_benign], ignore_index=True)

    # Preencher valores faltantes com 0 e manter apenas colunas numéricas
    data = data.fillna(0).select_dtypes(include=[float, int])

    # Separar características e rótulos
    X = data.drop('label', axis=1)
    y = data['label']

    # Dividir os dados em conjuntos de treinamento e teste
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

    # Treinar o modelo Random Forest
    model_rf = RandomForestClassifier(n_estimators=n_estimators, random_state=3)
    model_rf.fit(X_train, y_train)

    # Fazer previsões e calcular a acurácia
    y_pred = model_rf.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f'\nAcurácia do teste para {model_name}:', accuracy)

    # Gerar relatório de classificação
    report = classification_report(y_test, y_pred, target_names=['benigno', 'maligno'])
    print(f"\nRelatório de Classificação para {model_name}:\n", report)

    # Exibir a matriz de confusão
    conf_matrix = confusion_matrix(y_test, y_pred)
    print(f"Matriz de Confusão para {model_name}:\n", conf_matrix)

    # Gráfico de Matriz de Confusão
    plt.figure(figsize=(5, 4))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=['Benigno', 'Maligno'], yticklabels=['Benigno', 'Maligno'])
    plt.xlabel("Classe Predita")
    plt.ylabel("Classe Verdadeira")
    plt.title(f"Matriz de Confusão para {model_name}")
    plt.show()

    # Curva ROC
    y_pred_prob = model_rf.predict_proba(X_test)[:, 1]
    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
    roc_auc = auc(fpr, tpr)

    plt.figure(2)
    plt.plot(fpr, tpr, lw=2, label=f"{model_name} (área = {roc_auc:.2f})")
    plt.plot([0, 1], [0, 1], color='grey', linestyle='--')
    plt.xlabel("Taxa de Falso Positivo")
    plt.ylabel("Taxa de Verdadeiro Positivo")
    plt.title(f"Curva ROC para {model_name}")
    plt.legend(loc="lower right")
    plt.show()

    # Salvando o modelo treinado
    arquivo_pickle = f"RandomForest_{model_name}.sav"
    pickle.dump(model_rf, open(arquivo_pickle, 'wb'))

# Chamando a função para os três conjuntos de dados
train_and_evaluate_rf('api_calls_2b.csv', 'api_calls_2m.csv', 'API_Calls')
train_and_evaluate_rf('opcodes_2b.csv', 'opcodes_2m.csv', 'Opcodes')
train_and_evaluate_rf('permissions_2b.csv', 'permissions_2m.csv', 'Permissions')
